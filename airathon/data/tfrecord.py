# AUTOGENERATED! DO NOT EDIT! File to edit: tfrecord.ipynb (unless otherwise specified).

__all__ = ['Dataset', 'grid_metadata', 'get_grid_data', 'satellite_metadata', 'get_satellite_meta', 'fetch_subset',
           'maiac_subset_names', 'maiac_subset_indices', 'image_feature', 'float_feature', 'string_feature',
           'label_to_example', 'series_to_locations', 'series_to_subset_infos', 'row_to_label', 'create_tfrecord',
           'load_tfrecord']

# Cell
import os
import os.path as path
from typing import Tuple

import dateutil.parser as parser
import numpy as np
import pandas as pd
import skimage
import tensorflow as tf
from osgeo import gdal

import airathon.data as data
import airathon.paths as paths
from ..model.modis import load_modis

from tqdm import tqdm


Dataset = tf.data.Dataset

# Cell
grid_metadata = pd.read_csv(path.join(
    paths.dataset_metadata(), "grid_metadata.csv"))


# Cell
def get_grid_data(metadata: pd.DataFrame, grid_id: str) -> pd.DataFrame:
    return metadata[metadata["grid_id"] == grid_id]

# Cell
satellite_metadata = pd.read_csv(path.join(
    paths.dataset_metadata(), "satellite_metadata.csv"))

satellite_metadata['Date'] = pd.to_datetime(
    satellite_metadata['time_end'], format='%Y-%m-%d')

# Cell
def get_satellite_meta(
        metadata, datetime: str, location: str, datatype: str, split: str):
    if location == "Delhi":
        location = "dl"
    elif location == "Taipei":
        location = "tpe"
    else:
        location = "la"

    # filtering
    metadata = metadata[metadata['location'] == location]
    metadata = metadata[metadata['product'] == datatype]
    metadata = metadata[metadata['split'] == split]
    dateobject = parser.parse(datetime)

    return metadata.loc[(metadata['Date'].dt.month == dateobject.month) &
                        (metadata['Date'].dt.day == dateobject.day) &
                        (metadata['Date'].dt.year <= dateobject.year)]

# Cell
maiac_subset_names = [f"sds_{i}" for i in range(0, 13)]
maiac_subset_indices = [0, 3, 4, 8]

def fetch_subset(year: str, granule_id: str, split: str) -> dict:
    modis = load_modis(year, granule_id, split)
    subdataset = modis.GetSubDatasets()  # List[tuple]

    features = dict()
    rasters = list()

    for index in maiac_subset_indices:
        url, _ = subdataset[index]
        raster = gdal.Open(url)
        raster = raster.ReadAsArray()

        raster = np.swapaxes(raster, 0, 2)
        rasters.append(raster)

        raster = skimage.transform.resize(
            raster,
            output_shape=(240, 240, 4),
            anti_aliasing=False)

        features[maiac_subset_names[index]] = raster.astype(np.float32)

    return features

# Cell
def image_feature(image: np.ndarray):
    image = image.flatten()
    return tf.train.Feature(float_list=tf.train.FloatList(value=image))


def float_feature(v: float):
    return tf.train.Feature(float_list=tf.train.FloatList(value=[v]))


def string_feature(s: str):
    bs = bytes(s, "UTF-8")
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[bs]))

# Cell
def label_to_example(label: dict) -> tf.train.Example:
    feature = {
        "location": string_feature(label["location"]),
        "grid_id": string_feature(label["grid_id"]),
        "datetime": string_feature(label["datetime"]),
        "value": float_feature(label["value"])
    }

    del label["location"]
    del label["grid_id"]
    del label["datetime"]
    del label["value"]

    for name, image in label.items():
        feature[name] = image_feature(image)

    example = tf.train.Example(features=tf.train.Features(feature=feature))

    return example

# Cell
def series_to_locations(series):
    datetime = series["datetime"]  # type: str
    grid_id = series["grid_id"]
    grid_data = get_grid_data(grid_metadata, grid_id)
    location = grid_data.iloc[0]["location"]

    if location == "Delhi":
        location = "dl"
    elif location == "Taipei":
        location = "tpe"
    else:
        location = "la"

    return location


def series_to_subset_infos(series, split = "train"):
    datetime = series["datetime"]  # type: str
    grid_id = series["grid_id"]
    location = series["location"]

    satellite_data = get_satellite_meta(
        satellite_metadata,
        datetime,
        location,
        "maiac",  # or 'misr'
        split)

    infos = list()

    for i in range(len(satellite_data)):
        granule_id = satellite_data.iloc[i]['granule_id']
        time_end = parser.parse(satellite_data.iloc[i]["time_end"])

        infos.append((granule_id, time_end))

    return infos

def row_to_label(row, split):
    datetime = row["datetime"]  # type: str
    grid_id = row["grid_id"]
    location = row["location"]

    subset_infos = row["subset_info"]

    images = {}

    for index in maiac_subset_indices:
        name = maiac_subset_names[index]
        images[name] = list()

    for granule_id, time_end in subset_infos:
        new_images = fetch_subset(str(time_end.year), granule_id, split)

        for name, image in new_images.items():
            images[name].append(image)

    for index in maiac_subset_indices:
        name = maiac_subset_names[index]
        images_name = np.array(images[name])
        images[name] = images_name.mean(axis=0)

    label = {
        "location": location,
        "grid_id": grid_id,
        "datetime": datetime,
        "value": row["value"],
        **images
    }

    return label


# Cell
def create_tfrecord(dataframe: pd.DataFrame, split: str, path: str):
    dataframe = dataframe.copy()

    print("fetching locations...")
    dataframe["location"] = dataframe.apply(series_to_locations, axis=1)

    print("fetching subset_infos...")
    dataframe["subset_info"] = dataframe.apply(series_to_subset_infos, axis=1, split=split)

    with tf.io.TFRecordWriter(path) as writer, tqdm(total=len(dataframe)) as progress_bar:
        for _, row in dataframe.iterrows():
            label = row_to_label(row, split)
            example = label_to_example(label)

            writer.write(example.SerializeToString())

            progress_bar.update(1)


# Cell
def _decode(raw_person):
    spec = {
        "value": tf.io.FixedLenFeature([], dtype=tf.float32),
        "location": tf.io.FixedLenFeature([], dtype=tf.string),
        "datetime": tf.io.FixedLenFeature([], dtype=tf.string),
        "grid_id": tf.io.FixedLenFeature([], dtype=tf.string),
        # "sds_0": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_1": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_2": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_3": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_4": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_5": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_6": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_7": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_8": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_9": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_10": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_11": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
        # "sds_12": tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32),
    }

    for index in maiac_subset_indices:
        name = maiac_subset_names[index]
        spec[name] = tf.io.FixedLenFeature((240, 240, 4), dtype=tf.float32)

    return tf.io.parse_single_example(raw_person, spec)

# Cell
def load_tfrecord(path: str):
    return tf.data.TFRecordDataset(path).map(_decode)